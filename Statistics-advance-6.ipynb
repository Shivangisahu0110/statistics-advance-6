{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f14b59be-ccfe-4ff2-b057-fd9cd59ee5f8",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9ecd95-e934-412e-96c3-76c9ffe1508d",
   "metadata": {},
   "source": [
    "1. The population from which samples are drawn should be normally distributed.\n",
    "2. Independence of cases: the sample cases should be independent of each other.\n",
    "3. Homogeneity of variance: Homogeneity means that the variance among the groups should be approximately equal.\n",
    "4. Random Sampling: The data are collected through random sampling from the population of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1512fb9f-0935-4493-a2bb-e364d41b1ffa",
   "metadata": {},
   "source": [
    "Examples of violations and their impacts on validity:\n",
    "\n",
    "1. Non-Normality: If the residuals are not normally distributed, the p-values and confidence intervals generated by ANOVA may be inaccurate. \n",
    "\n",
    "2. Homoscedasticity: When the assumption of equal variances is violated, the F-test in ANOVA becomes less reliable. \n",
    "3. Independence: Violation of independence assumptions, such as in repeated measures designs or clustered data, can lead to biased estimates of variability and inflated Type I error rates.\n",
    "\n",
    "4. Random Sampling: If the sampling process is not random, the generalizability of the results may be compromised."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96770f46-47cf-42d3-9b30-b16ca33c3b38",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7c6cfc-d77d-43a7-ad9d-81aea3cca817",
   "metadata": {},
   "source": [
    "\n",
    "The three main types of ANOVA are:\n",
    "\n",
    "One-Way ANOVA: This type of ANOVA is used when you have one categorical independent variable (with three or more levels) and one continuous dependent variable. It tests whether the means of the dependent variable are equal across all levels of the independent variable. One-way ANOVA is appropriate when you want to compare the means of multiple groups simultaneously. For example, you might use one-way ANOVA to determine if there are differences in test scores among students who studied under different teaching methods (e.g., traditional lecture, online modules, group projects).\n",
    "\n",
    "Two-Way ANOVA: Two-way ANOVA is used when you have two categorical independent variables (factors) and one continuous dependent variable. It examines the main effects of each independent variable as well as the interaction between them. Two-way ANOVA is suitable for situations where you want to explore how two factors individually and together influence the dependent variable. For instance, in a study on the effects of both diet and exercise on weight loss, you might have one independent variable representing diet type (e.g., low-carb, low-fat) and another representing exercise intensity (e.g., high, moderate, low).\n",
    "\n",
    "Repeated Measures ANOVA: This type of ANOVA is used when you have one categorical independent variable (with three or more levels) and one continuous dependent variable, but the same participants are measured under all conditions or at multiple time points. Repeated measures ANOVA is appropriate when you want to assess changes within subjects over time or across different conditions. For example, in a study investigating the effects of three different treatments on pain relief over time, participants' pain levels might be measured before treatment, immediately after treatment, and at regular intervals afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c20035-4483-4365-ab64-9dff9bc89eba",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4c3a09-82fc-4f7d-921e-a9936e122102",
   "metadata": {},
   "source": [
    "Total Variance (Total Sum of Squares, SST): This represents the total variability in the dependent variable across all observations.\n",
    "\n",
    "Between-Group Variance (Between-Group Sum of Squares, SSB): This represents the variability in the dependent variable that can be attributed to the differences between the group means.\n",
    "\n",
    "Within-Group Variance (Within-Group Sum of Squares, SSW or SSE): This represents the variability in the dependent variable that cannot be explained by the differences between the group means. It reflects the variability within each group or condition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3df12a2-f187-4d8a-8347-e4a875e8c5a0",
   "metadata": {},
   "source": [
    "The partitioning of variance is important for several reasons:\n",
    "\n",
    "Assessment of Group Differences: By partitioning the total variance into between-group and within-group components, ANOVA allows us to determine whether the differences observed between groups are statistically significant. If the between-group variance is significantly greater than the within-group variance, it suggests that there are significant differences between the group means.\n",
    "\n",
    "Effect Size Estimation: Understanding the proportion of variance explained by the independent variable(s) (i.e., between-group variance) relative to the total variance provides insight into the magnitude of the effect. Effect size measures such as eta-squared (η²) or partial eta-squared (η²_p) are calculated based on the partitioning of variance.\n",
    "\n",
    "Hypothesis Testing: The partitioning of variance forms the basis for hypothesis testing in ANOVA. The F-statistic, which is calculated as the ratio of between-group variance to within-group variance (F = SSB / SSW), is used to determine whether the observed differences between group means are statistically significant.\n",
    "\n",
    "Model Evaluation: Partitioning of variance helps in evaluating the fit of the ANOVA model to the data. It allows researchers to assess how well the model accounts for the observed variability in the dependent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb38604-e411-4cba-b632-5d9d2324aaca",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b24d4a9-aa3a-44bb-92af-05bcf1bd79d7",
   "metadata": {},
   "source": [
    "Calculate the Mean: Calculate the overall mean of the dependent variable.\n",
    "\n",
    "Calculate the Total Sum of Squares (SST): Calculate the sum of squared deviations of each observation from the overall mean.\n",
    "\n",
    "Calculate the Explained Sum of Squares (SSE): Calculate the sum of squared deviations of each group mean from the overall mean, weighted by the number of observations in each group.\n",
    "\n",
    "Calculate the Residual Sum of Squares (SSR): Calculate the sum of squared deviations of each observation from its group mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21e88f70-bff5-4754-81d7-2b3b854babde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 290.0\n",
      "Explained Sum of Squares (SSE): 12.666666666666666\n",
      "Residual Sum of Squares (SSR): 277.3333333333333\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "group_means = [10, 15, 12]  # Means of each group\n",
    "group_sizes = [20, 25, 30]   # Number of observations in each group\n",
    "overall_mean = np.mean(group_means)  # Overall mean of the dependent variable\n",
    "\n",
    "# Calculate SST\n",
    "SST = np.sum([(group_means[i] - overall_mean)**2 * group_sizes[i] for i in range(len(group_means))])\n",
    "\n",
    "# Calculate SSE\n",
    "SSE = np.sum([(group_means[i] - overall_mean)**2 for i in range(len(group_means))])\n",
    "\n",
    "# Calculate SSR\n",
    "SSR = SST - SSE\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", SST)\n",
    "print(\"Explained Sum of Squares (SSE):\", SSE)\n",
    "print(\"Residual Sum of Squares (SSR):\", SSR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06b4eed-0695-4ce9-b572-338fca192ebb",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b3505-ce2e-4cd9-88be-d7be13752a41",
   "metadata": {},
   "source": [
    "In this case, you obtained an F-statistic of 5.23 and a p-value of 0.02. Here's how to interpret these results:\n",
    "\n",
    "Significance of the F-Statistic: The F-statistic of 5.23 indicates that there is some variability between the group means relative to the variability within the groups. However, to determine whether this variability is statistically significant, we need to consider the p-value.\n",
    "\n",
    "Interpretation of the p-value: The p-value of 0.02 means that if the null hypothesis (that the means of all groups are equal) is true, there is only a 2% probability of observing the data or more extreme results. Typically, if the p-value is less than a predetermined significance level (e.g., 0.05), we reject the null hypothesis in favor of the alternative hypothesis.\n",
    "\n",
    "Conclusion: With a p-value of 0.02, we would reject the null hypothesis and conclude that there are statistically significant differences between the groups. In other words, at least one group mean is different from the others.\n",
    "\n",
    "Practical Significance: While the results are statistically significant, it's also important to consider the practical significance of the differences between the groups. Even though the differences are statistically significant, they may not be practically significant if they are small or negligible in magnitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50558074-3f44-4873-846e-a7a53780aedc",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e267d91c-3422-4a3d-8456-9a81dc67d7b5",
   "metadata": {},
   "source": [
    "1. Complete Case Analysis (Listwise Deletion):\n",
    "\n",
    "Method: Exclude any cases with missing data on any variable included in the analysis.\n",
    "\n",
    "Consequences: Reduces sample size and statistical power, potentially leading to biased estimates if missingness is related to the outcome or other variables.\n",
    "\n",
    "2. Mean/Median Imputation:\n",
    "\n",
    "Method: Replace missing values with the mean or median of the observed values for that variable.\n",
    "\n",
    "Consequences: Alters the distribution of the data, underestimates standard errors, and reduces variability, potentially leading to biased estimates and inaccurate hypothesis tests.\n",
    "\n",
    "3. Last Observation Carried Forward (LOCF):\n",
    "\n",
    "Method: Use the last observed value for each participant to replace missing values.\n",
    "\n",
    "Consequences: Assumes that the last observed value accurately represents the missing data, which may not always be true and can lead to biased estimates, particularly if there is systematic change over time.\n",
    "\n",
    "4. Multiple Imputation:\n",
    "\n",
    "Method: Generate multiple plausible values for each missing data point based on the observed data and uncertainty about the missing values. Analyze each imputed dataset separately and then combine the results.\n",
    "\n",
    "Consequences: Preserves variability and more accurately reflects uncertainty, but can be computationally intensive and may require assumptions about the missing data mechanism.\n",
    "\n",
    "5. Model-Based Imputation:\n",
    "\n",
    "Method: Use regression or other statistical models to predict missing values based on observed data.\n",
    "\n",
    "Consequences: Preserves variability and can provide more accurate estimates if the imputation model is correctly specified, but relies on assumptions about the relationship between the variables.\n",
    "\n",
    "6. Weighted Estimation:\n",
    "\n",
    "Method: Give more weight to observations with complete data and less weight to observations with missing data.\n",
    "\n",
    "Consequences: Can reduce bias compared to complete case analysis, but may still lead to biased estimates if missingness is related to the outcome or other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adec27f9-ad9b-4313-8725-676f909d8b46",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33b4e32-56aa-4b4a-9ffb-9295dc187b2d",
   "metadata": {},
   "source": [
    "Post-hoc tests are used after conducting an ANOVA to determine which specific group means differ significantly from each other when the overall ANOVA test indicates that there is a significant difference between groups. Some common post-hoc tests include:\n",
    "\n",
    "1. Tukey's Honestly Significant Difference (HSD):\n",
    "\n",
    "When to use: Tukey's HSD is typically used when you have three or more groups and you want to conduct all possible pairwise comparisons while controlling the overall Type I error rate. It is considered one of the most conservative post-hoc tests.\n",
    "\n",
    "Example: In a study comparing the effectiveness of three different teaching methods (traditional lecture, online modules, and group projects) on student performance, Tukey's HSD can be used to determine which pairs of teaching methods differ significantly in terms of average test scores.\n",
    "\n",
    "2. Bonferroni Correction:\n",
    "\n",
    "When to use: The Bonferroni correction is a simple method to control the familywise error rate when conducting multiple comparisons. It adjusts the significance level (α) for each individual comparison to maintain an overall desired alpha level.\n",
    "\n",
    "Example: In a clinical trial comparing the efficacy of four different treatments for a medical condition, the Bonferroni correction can be used to compare each treatment to every other treatment while controlling for the increased risk of Type I error due to multiple comparisons.\n",
    "\n",
    "3. Sidak Correction:\n",
    "\n",
    "When to use: Similar to the Bonferroni correction, the Sidak correction adjusts the significance level for multiple comparisons to maintain an overall desired alpha level. It is less conservative than Bonferroni when the number of comparisons is large.\n",
    "\n",
    "Example: In a market research study comparing the sales performance of multiple product variations across different regions, the Sidak correction can be applied to determine which specific product variations significantly differ in sales.\n",
    "\n",
    "4. Dunnett's Test:\n",
    "\n",
    "When to use: Dunnett's test is used when you have one control group and several treatment groups, and you want to compare each treatment group to the control group while controlling the overall Type I error rate.\n",
    "\n",
    "Example: In a study evaluating the effectiveness of different doses of a new medication compared to a placebo, Dunnett's test can be used to determine if any of the medication doses lead to significantly different outcomes compared to the placebo.\n",
    "\n",
    "5. Holm's Sequential Bonferroni Procedure:\n",
    "\n",
    "When to use: Holm's procedure is a step-down method that adjusts the significance level for multiple comparisons while maintaining control over the familywise error rate. It starts by testing the most significant comparison and progressively adjusts the significance level for subsequent comparisons.\n",
    "\n",
    "Example: In a study investigating the impact of various marketing strategies on sales revenue across different demographics, Holm's procedure can be used to identify specific demographic groups where the marketing strategies have a significant effect on sales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259ae9f2-90a5-40a5-b745-934a4c84bbcb",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b536f83-0eb7-49ae-acf5-4685d0b9d5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 126.29272898961278\n",
      "p-value: 2.8584049603842127e-24\n",
      "The p-value is less than 0.05 so we reject the null hypothesis.\n",
      "There is sufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Sample data\n",
    "diet_A = np.array([2.1, 1.9, 2.5, 2.3, 2.2, 1.8, 2.0, 2.4, 2.6, 2.3,\n",
    "                   2.1, 2.4, 2.0, 2.2, 2.5, 2.3, 2.1, 2.3, 2.6, 2.4,\n",
    "                   2.1, 2.0, 2.3, 2.5, 2.2])\n",
    "diet_B = np.array([2.3, 2.7, 2.5, 2.4, 2.6, 2.8, 2.9, 2.5, 2.7, 2.6,\n",
    "                   2.3, 2.4, 2.6, 2.7, 2.8, 2.9, 2.5, 2.4, 2.6, 2.7,\n",
    "                   2.3, 2.4, 2.6, 2.8, 2.7])\n",
    "diet_C = np.array([2.8, 3.0, 3.2, 2.9, 3.1, 3.0, 2.8, 3.2, 3.1, 3.3,\n",
    "                   3.0, 3.2, 3.1, 3.0, 2.9, 3.3, 3.0, 3.1, 3.2, 3.4,\n",
    "                   2.9, 3.0, 3.2, 3.1, 3.3])\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Report the results\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05\n",
    "if p_value < alpha:\n",
    "    print(\"The p-value is less than\", alpha, \"so we reject the null hypothesis.\")\n",
    "    print(\"There is sufficient evidence to conclude that there are significant differences between the mean weight loss of the three diets.\")\n",
    "else:\n",
    "    print(\"The p-value is greater than or equal to\", alpha, \"so we fail to reject the null hypothesis.\")\n",
    "    print(\"There is not enough evidence to conclude that there are significant differences between the mean weight loss of the three diets.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc137f69-4189-44d3-84e3-81c23e823156",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4a35757-9f73-47e9-9e26-0024c3bddbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame:\n",
      "   Software_Program Experience_Level  Task_Time\n",
      "0                 A           Novice         15\n",
      "1                 A      Experienced         10\n",
      "2                 A           Novice         13\n",
      "3                 A      Experienced         13\n",
      "4                 A           Novice         17\n",
      "5                 A      Experienced         19\n",
      "6                 A           Novice         13\n",
      "7                 A      Experienced         15\n",
      "8                 A           Novice         12\n",
      "9                 A      Experienced         14\n",
      "10                A           Novice         17\n",
      "11                A      Experienced         16\n",
      "12                A           Novice         18\n",
      "13                A      Experienced         18\n",
      "14                A           Novice         11\n",
      "15                A      Experienced         16\n",
      "16                A           Novice         17\n",
      "17                A      Experienced         17\n",
      "18                A           Novice         18\n",
      "19                A      Experienced         11\n",
      "20                B           Novice         15\n",
      "21                B      Experienced         19\n",
      "22                B           Novice         18\n",
      "23                B      Experienced         19\n",
      "24                B           Novice         14\n",
      "25                B      Experienced         13\n",
      "26                B           Novice         10\n",
      "27                B      Experienced         13\n",
      "28                B           Novice         15\n",
      "29                B      Experienced         10\n",
      "30                B           Novice         12\n",
      "31                B      Experienced         13\n",
      "32                B           Novice         18\n",
      "33                B      Experienced         11\n",
      "34                B           Novice         13\n",
      "35                B      Experienced         13\n",
      "36                B           Novice         13\n",
      "37                B      Experienced         17\n",
      "38                B           Novice         10\n",
      "39                B      Experienced         11\n",
      "40                C           Novice         19\n",
      "41                C      Experienced         19\n",
      "42                C           Novice         10\n",
      "43                C      Experienced         14\n",
      "44                C           Novice         17\n",
      "45                C      Experienced         13\n",
      "46                C           Novice         12\n",
      "47                C      Experienced         17\n",
      "48                C           Novice         12\n",
      "49                C      Experienced         10\n",
      "50                C           Novice         10\n",
      "51                C      Experienced         14\n",
      "52                C           Novice         15\n",
      "53                C      Experienced         15\n",
      "54                C           Novice         16\n",
      "55                C      Experienced         18\n",
      "56                C           Novice         14\n",
      "57                C      Experienced         11\n",
      "58                C           Novice         14\n",
      "59                C      Experienced         19\n",
      "\n",
      "Main Effects:\n",
      "                        sum_sq   df         F    PR(>F)\n",
      "C(Software_Program)  13.233333  2.0  0.745618  0.479262\n",
      "C(Experience_Level)   1.666667  1.0  0.187813  0.666469\n",
      "\n",
      "Interaction Effect:\n",
      "sum_sq    479.2\n",
      "df         54.0\n",
      "F           NaN\n",
      "PR(>F)      NaN\n",
      "Name: Residual, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Define constants\n",
    "num_employees_per_program = 10\n",
    "num_levels_per_factor = 2\n",
    "\n",
    "# Generate software programs\n",
    "software_programs = np.repeat(['A', 'B', 'C'], num_employees_per_program * num_levels_per_factor)\n",
    "\n",
    "# Generate experience levels to match the length of software_programs\n",
    "experience_levels = np.tile(['Novice', 'Experienced'], len(software_programs) // 2)\n",
    "\n",
    "# Generate random task times\n",
    "np.random.seed(0)  # for reproducibility\n",
    "task_times = np.random.randint(10, 20, size=len(software_programs))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({'Software_Program': software_programs, 'Experience_Level': experience_levels, 'Task_Time': task_times})\n",
    "\n",
    "# Print DataFrame\n",
    "print(\"\\nDataFrame:\")\n",
    "print(df)\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('Task_Time ~ C(Software_Program) + C(Experience_Level) + C(Software_Program):C(Experience_Level)', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Extract main effects and interaction effects from the ANOVA table\n",
    "main_effects = anova_table[['sum_sq', 'df', 'F', 'PR(>F)']].iloc[:2]\n",
    "interaction_effect = anova_table[['sum_sq', 'df', 'F', 'PR(>F)']].iloc[-1]\n",
    "\n",
    "print(\"\\nMain Effects:\")\n",
    "print(main_effects)\n",
    "print(\"\\nInteraction Effect:\")\n",
    "print(interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f2e2f4-273c-4712-a121-bd0546cb5dec",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05517863-0229-4a0d-a292-0145e47c22cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test results:\n",
      "t-statistic: -3.597192759749614\n",
      "p-value: 0.0004062796020362504\n",
      "The difference in test scores between the two groups is statistically significant.\n",
      "\n",
      "Post-hoc (Tukey's HSD) test results:\n",
      "   Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "=========================================================\n",
      " group1    group2    meandiff p-adj  lower  upper  reject\n",
      "---------------------------------------------------------\n",
      "Control Experimental    5.222 0.0004 2.3593 8.0848   True\n",
      "---------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate random test scores for the control and experimental groups\n",
    "np.random.seed(0)  # for reproducibility\n",
    "control_group_scores = np.random.normal(loc=70, scale=10, size=100)  # mean=70, std=10\n",
    "experimental_group_scores = np.random.normal(loc=75, scale=10, size=100)  # mean=75, std=10\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = ttest_ind(control_group_scores, experimental_group_scores)\n",
    "print(\"Two-sample t-test results:\")\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the difference is significant (using alpha = 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference in test scores between the two groups is statistically significant.\")\n",
    "    \n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    all_scores = np.concatenate([control_group_scores, experimental_group_scores])\n",
    "    group_labels = ['Control'] * 100 + ['Experimental'] * 100\n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels, alpha=0.05)\n",
    "    print(\"\\nPost-hoc (Tukey's HSD) test results:\")\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49723d48-68c2-4b4f-9e11-b37f395c5e01",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a72d2fa-46a9-4b40-a508-0239afb03215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repeated Measures ANOVA results:\n",
      "               Anova\n",
      "===================================\n",
      "      F Value Num DF  Den DF Pr > F\n",
      "-----------------------------------\n",
      "Store  3.1805 2.0000 58.0000 0.0489\n",
      "===================================\n",
      "\n",
      "\n",
      "One-way ANOVA results:\n",
      "F-statistic: 3.3414606706069834\n",
      "p-value: 0.039981492411499175\n",
      "\n",
      "The overall difference in sales between the three stores is statistically significant.\n",
      "\n",
      "Post-hoc (Tukey's HSD) test results:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      " group1  group2 meandiff p-adj   lower    upper  reject\n",
      "-------------------------------------------------------\n",
      "Store A Store B  -4.6476 0.6397 -16.9155  7.6203  False\n",
      "Store A Store C   8.4685 0.2321  -3.7994 20.7363  False\n",
      "Store B Store C   13.116 0.0333   0.8481 25.3839   True\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from scipy.stats import f_oneway\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Generate sample data for daily sales of three stores\n",
    "np.random.seed(0)  # for reproducibility\n",
    "store_a_sales = np.random.normal(loc=100, scale=20, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=20, size=30)\n",
    "store_c_sales = np.random.normal(loc=120, scale=20, size=30)\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Day': np.arange(1, 31), \n",
    "    'Store_A_Sales': store_a_sales, \n",
    "    'Store_B_Sales': store_b_sales, \n",
    "    'Store_C_Sales': store_c_sales\n",
    "})\n",
    "\n",
    "# Melt the DataFrame for repeated measures ANOVA\n",
    "melted_df = pd.melt(df, id_vars=['Day'], value_vars=['Store_A_Sales', 'Store_B_Sales', 'Store_C_Sales'],\n",
    "                     var_name='Store', value_name='Sales')\n",
    "\n",
    "# Perform repeated measures ANOVA\n",
    "rm_anova = AnovaRM(melted_df, 'Sales', 'Day', within=['Store']).fit()\n",
    "print(\"Repeated Measures ANOVA results:\")\n",
    "print(rm_anova)\n",
    "\n",
    "# Perform one-way ANOVA (to check overall significance)\n",
    "f_stat, p_value = f_oneway(store_a_sales, store_b_sales, store_c_sales)\n",
    "print(\"\\nOne-way ANOVA results:\")\n",
    "print(\"F-statistic:\", f_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the overall difference is significant (using alpha = 0.05)\n",
    "if p_value < 0.05:\n",
    "    print(\"\\nThe overall difference in sales between the three stores is statistically significant.\")\n",
    "\n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    all_sales = np.concatenate([store_a_sales, store_b_sales, store_c_sales])\n",
    "    group_labels = ['Store A'] * 30 + ['Store B'] * 30 + ['Store C'] * 30\n",
    "    tukey_results = pairwise_tukeyhsd(all_sales, group_labels, alpha=0.05)\n",
    "    print(\"\\nPost-hoc (Tukey's HSD) test results:\")\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"\\nThere is no significant difference in sales between the three stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8778222-6682-4bb3-8b4c-db3eeb757aae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
